{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG w/ Gemini\n",
    "\n",
    "#### *RAG 프로세스: 문서 로드 및 Vector DB 저장*\n",
    "1. 문서 로드 (load): 문서(pdf, word), RAW DATA, 웹페이지, notion 등의 데이터 읽기\n",
    "2. 분할 (split): 불러온 문서를 chunk 단위로 분할\n",
    "3. 임베딩 (embedding): 문서를 벡터 표현으로 변환\n",
    "4. 벡터DB(VectorStore): 변환된 벡터를 DB에 저장\n",
    "\n",
    "<br>\n",
    "\n",
    "#### *RAG 프로세스: 문서 검색 및 결과 도출*\n",
    "5. 검색 (retrieval): 유사도 검색(similarity, mmr), Multi-Query, Multi-Retriever\n",
    "6. 프롬프트 (prompt): 검색된 결과를 바탕으로 원하는 결과를 도출하기 위한 프롬프트\n",
    "7. 모델 (LLM): 모델 선택 (gpt, gemini, etc.)\n",
    "8. 결과 (output): 텍스트, JSON, markdown\n",
    "\n",
    "<br><hr>\n",
    "\n",
    "- 예제\n",
    "  - 데이터: 한국산업은행 금융관련 용어 csv 파일\n",
    "  - 임베딩: 업스테이지 모델\n",
    "  - 벡터 스토어: 크로마 DB\n",
    "\n",
    "<br>\n",
    "\n",
    "- 변경\n",
    "  - 데이터: 제주도 맛집 정보\n",
    "  - 임베딩: 허깅페이스 모델\n",
    "    - intfloat/multilingual-e5-large-instruct\n",
    "    - jhgan/ko-sroberta-multitask\n",
    "    - upskyy/bge-m3-Korean\n",
    "  - 벡터스토어: 크로마 DB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "bigcon_langchain_test\n"
     ]
    }
   ],
   "source": [
    "# 랭스미스 추적\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름 입력\n",
    "logging.langsmith(\"bigcon_langchain_test\")\n",
    "\n",
    "# 추적을 끄고 싶은 경우\n",
    "# logging.langsmith(\"bigcon_langchain_test\", set_enable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# 디버깅을 위한 프로젝트명\n",
    "os.environ[\"bigcon_langchain_test\"] = \"RAG TUTORIAL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서의 수: 1003\n",
      "\n",
      "[페이지내용]\n",
      "YM: 202303\n",
      "MCT_NM: 주식회사웨이뷰\n",
      "OP_YMD: 20230207\n",
      "TYPE: T30\n",
      "MCT_TYPE: 햄버거\n",
      "temp_05_11: 11.25069124\n",
      "temp_12_13: 13.04193548\n",
      "temp_14_17: 13.04596774\n",
      "temp_18_22: 11.43225806\n",
      "temp_23_04: 10.67473118\n",
      "TEMP_AVG: 11.88911674\n",
      "latitude: 33.4073014\n",
      "longitude: 126.2530211\n",
      "Polygon: P5\n",
      "area: 서부\n",
      "ADDR: 제주 제주시 한림읍 옹포리 419-3번지\n",
      "RANK_CNT: 1\n",
      "RANK_AMT: 1\n",
      "RANK_MEAN: 5\n",
      "MON_UE_CNT_RAT: 0.1325695581\n",
      "TUE_UE_CNT_RAT: 0.1309328969\n",
      "WED_UE_CNT_RAT: 0.1554828151\n",
      "THU_UE_CNT_RAT: 0.124386252\n",
      "FRI_UE_CNT_RAT: 0.1080196399\n",
      "SAT_UE_CNT_RAT:\n",
      "\n",
      "[metadata]\n",
      "{'source': '..\\\\data\\\\sample_1000_with_meta.csv', 'row': 10}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1) 문서 로드\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "loader = CSVLoader(\n",
    "  file_path=\"..\\data\\sample_1000_with_meta.csv\",\n",
    "  encoding=\"cp949\"\n",
    ")\n",
    "pages = loader.load()\n",
    "print(f\"문서의 수: {len(pages)}\")\n",
    "\n",
    "# 10번째 페이지의 내용 확인\n",
    "print(f\"\\n[페이지내용]\\n{pages[10].page_content[:500]}\")\n",
    "print(f\"\\n[metadata]\\n{pages[10].metadata}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\workspaces\\llmGeminiTest\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 2) 허깅페이스 모델을 사용하여 임베딩 생성 \n",
    "# from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"jhgan/ko-sroberta-multitask\")\n",
    "# model = AutoModel.from_pretrained(\"jhgan/ko-sroberta-multitask\")\n",
    "\n",
    "# for page in pages:\n",
    "#     text = page.page_content\n",
    "#     inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "#     embedding = model(**inputs).last_hidden_state.mean(dim=1)  # 평균 풀링으로 임베딩 생성\n",
    "\n",
    "### >> 이 방식은 <임베딩 계산 방식을 세밀히 제어해야 하는 경우>에 추천"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_15508\\990583999.py:5: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"jhgan/ko-sroberta-multitask\")\n",
      "c:\\workspaces\\llmGeminiTest\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 2) 허깅페이스 모델을 사용하여 임베딩 생성 \n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# HuggingFace 임베딩 클래스 사용\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"jhgan/ko-sroberta-multitask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "벡터스토어에 저장된 문서 수: 2006\n"
     ]
    }
   ],
   "source": [
    "# 3) Chroma 벡터스토어에 저장\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# Chroma 인스턴스 생성\n",
    "vectorstore = Chroma.from_documents(pages, embeddings, persist_directory=\"./database\")\n",
    "\n",
    "# 벡터스토어에 저장된 정보 확인\n",
    "print(f\"벡터스토어에 저장된 문서 수: {len(vectorstore)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) MMR 검색기 생성\n",
    "# 벡터스토어 객체는 코사인 유사도/유클리디언 거리/MMR(Maximal Marginal Relevance) 등의 검색 방법이 있음\n",
    "# >> MMR 방식 사용 >> 질의어와 관련성이 높으면서도 다양한 문서를 검색하기 위함\n",
    "\n",
    "### MMR 검색 기법 작동 과정\n",
    "# 1) 질의어와 관련성이 높은 문서 fetch_k 개를 가져옴\n",
    "# 2) fetch_k개의 문서에 대해 이터레이션을 돌면서 질의어와 관련성이 높으면서도 이전 이터레이션에서 이미 선택된 문서와는 유사성이 낮은 문서를 가져옴\n",
    "# 3) 총 k개를 가져올 때까지 2번을 반복\n",
    "\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"mmr\", search_kwargs={\"k\": 5, \"fetch_k\": 10}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) 프롬프트 템플릿 생성\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# 검색 결과는 {context}에, 질의는 {query}에 들어감\n",
    "\n",
    "template = \"\"\"\n",
    "[context]: {context}\n",
    "---\n",
    "[질의]: {query}\n",
    "---\n",
    "[예시]\n",
    "제주도 (area)에 위치한 (사용자의 요구) 맛집을 추천드립니다.\n",
    "[MCT_NM]은 [area]에 위치한 [MCT_TYPE] 맛집입니다. [특징] 설명, [ADDR]에 위치하고 있습니다.\n",
    "3~5개 추천\n",
    "---\n",
    "위의 [context] 정보 내에서 [질의]에 대해 답변 [예시]와 같이 술어를 붙여서 답하세요. 특징은 제공한 데이터 내에서만 답하세요.\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGoogleGenerativeAI(model='models/gemini-1.5-flash', google_api_key=SecretStr('**********'), temperature=0.5, client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x000002BAA868CFD0>, default_metadata=())"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6) 제미나이 모델 객체 가져오기\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# test할 때는 답변의 일관성을 높이기 위해 일단 temp=0으로 설정\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.5)\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) 검색 결과 가공\n",
    "# 원천 데이터에는 레코드, 필드 등 데이터 구조에 대한 정보 + 불필요한 메타 정보가 같이 있음\n",
    "# merge_pages 함수로 원천 정보 중 page_content 정보만 가져오고 페이지 간에는 두 개의 개행을 적용하여 하나의 문서로 병합하는 작업을 수행\n",
    "# 어떤 정보가 검색되었는지 확인하기 위해 print\n",
    "\n",
    "def merge_pages(pages):\n",
    "    merged = \"\\n\\n\".join(page.page_content for page in pages)\n",
    "    print(f\"참조 문서 시작==>[\\n{merged}\\n]<==참조 문서 끝\")\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) 체이닝 구성\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 프롬프트, LLM, 검색기, 검색결과 가공함수를 연결하여 체인을 구성\n",
    "chain = (\n",
    "    {\"query\": RunnablePassthrough(), \"context\": retriever | merge_pages}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "참조 문서 시작==>[\n",
      "YM: 202307\n",
      "MCT_NM: 제주포레스트주식회사 포메인제주노형점\n",
      "OP_YMD: 20200420\n",
      "TYPE: T9\n",
      "MCT_TYPE: 동남아/인도음식\n",
      "temp_05_11: 27.58110599\n",
      "temp_12_13: 29.90322581\n",
      "temp_14_17: 29.92258065\n",
      "temp_18_22: 28.15612903\n",
      "temp_23_04: 26.80430108\n",
      "TEMP_AVG: 28.47346851\n",
      "latitude: 33.4842637\n",
      "longitude: 126.4798582\n",
      "Polygon: P3\n",
      "area: 북부\n",
      "ADDR: 제주 제주시 노형동 3783-2번지 3층\n",
      "RANK_CNT: 3\n",
      "RANK_AMT: 3\n",
      "RANK_MEAN: 4\n",
      "MON_UE_CNT_RAT: 0.1475409836\n",
      "TUE_UE_CNT_RAT: 0.1557377049\n",
      "WED_UE_CNT_RAT: 0.1967213115\n",
      "THU_UE_CNT_RAT: 0.106557377\n",
      "FRI_UE_CNT_RAT: 0.1147540984\n",
      "SAT_UE_CNT_RAT: 0.09836065574\n",
      "SUN_UE_CNT_RAT: 0.1803278689\n",
      "HR_5_11_UE_CNT_RAT: 0.04098360656\n",
      "HR_12_13_UE_CNT_RAT: 0.393442623\n",
      "HR_14_17_UE_CNT_RAT: 0.2704918033\n",
      "HR_18_22_UE_CNT_RAT: 0.2950819672\n",
      "HR_23_4_UE_CNT_RAT: 0.0\n",
      "LOCAL_UE_CNT_RAT: 0.6627218935\n",
      "RC_M12_MAL_CUS_CNT_RAT: 0.396\n",
      "RC_M12_FME_CUS_CNT_RAT: 0.604\n",
      "RC_M12_AGE_UND_20_CUS_CNT_RAT: 0.138\n",
      "RC_M12_AGE_30_CUS_CNT_RAT: 0.268\n",
      "RC_M12_AGE_40_CUS_CNT_RAT: 0.351\n",
      "RC_M12_AGE_50_CUS_CNT_RAT: 0.18\n",
      "RC_M12_AGE_OVR_60_CUS_CNT_RAT: 0.064\n",
      "\n",
      "YM: 202307\n",
      "MCT_NM: 제주포레스트주식회사 포메인제주노형점\n",
      "OP_YMD: 20200420\n",
      "TYPE: T9\n",
      "MCT_TYPE: 동남아/인도음식\n",
      "temp_05_11: 27.58110599\n",
      "temp_12_13: 29.90322581\n",
      "temp_14_17: 29.92258065\n",
      "temp_18_22: 28.15612903\n",
      "temp_23_04: 26.80430108\n",
      "TEMP_AVG: 28.47346851\n",
      "latitude: 33.4842637\n",
      "longitude: 126.4798582\n",
      "Polygon: P3\n",
      "area: 북부\n",
      "ADDR: 제주 제주시 노형동 3783-2번지 3층\n",
      "RANK_CNT: 3\n",
      "RANK_AMT: 3\n",
      "RANK_MEAN: 4\n",
      "MON_UE_CNT_RAT: 0.1475409836\n",
      "TUE_UE_CNT_RAT: 0.1557377049\n",
      "WED_UE_CNT_RAT: 0.1967213115\n",
      "THU_UE_CNT_RAT: 0.106557377\n",
      "FRI_UE_CNT_RAT: 0.1147540984\n",
      "SAT_UE_CNT_RAT: 0.09836065574\n",
      "SUN_UE_CNT_RAT: 0.1803278689\n",
      "HR_5_11_UE_CNT_RAT: 0.04098360656\n",
      "HR_12_13_UE_CNT_RAT: 0.393442623\n",
      "HR_14_17_UE_CNT_RAT: 0.2704918033\n",
      "HR_18_22_UE_CNT_RAT: 0.2950819672\n",
      "HR_23_4_UE_CNT_RAT: 0.0\n",
      "LOCAL_UE_CNT_RAT: 0.6627218935\n",
      "RC_M12_MAL_CUS_CNT_RAT: 0.396\n",
      "RC_M12_FME_CUS_CNT_RAT: 0.604\n",
      "RC_M12_AGE_UND_20_CUS_CNT_RAT: 0.138\n",
      "RC_M12_AGE_30_CUS_CNT_RAT: 0.268\n",
      "RC_M12_AGE_40_CUS_CNT_RAT: 0.351\n",
      "RC_M12_AGE_50_CUS_CNT_RAT: 0.18\n",
      "RC_M12_AGE_OVR_60_CUS_CNT_RAT: 0.064\n",
      "\n",
      "YM: 202307\n",
      "MCT_NM: 제주포레스트주식회사 포메인제주노형점\n",
      "OP_YMD: 20200420\n",
      "TYPE: T9\n",
      "MCT_TYPE: 동남아/인도음식\n",
      "temp_05_11: 27.58110599\n",
      "temp_12_13: 29.90322581\n",
      "temp_14_17: 29.92258065\n",
      "temp_18_22: 28.15612903\n",
      "temp_23_04: 26.80430108\n",
      "TEMP_AVG: 28.47346851\n",
      "latitude: 33.4842637\n",
      "longitude: 126.4798582\n",
      "Polygon: P3\n",
      "area: 북부\n",
      "ADDR: 제주 제주시 노형동 3783-2번지 3층\n",
      "RANK_CNT: 3\n",
      "RANK_AMT: 3\n",
      "RANK_MEAN: 4\n",
      "MON_UE_CNT_RAT: 0.1475409836\n",
      "TUE_UE_CNT_RAT: 0.1557377049\n",
      "WED_UE_CNT_RAT: 0.1967213115\n",
      "THU_UE_CNT_RAT: 0.106557377\n",
      "FRI_UE_CNT_RAT: 0.1147540984\n",
      "SAT_UE_CNT_RAT: 0.09836065574\n",
      "SUN_UE_CNT_RAT: 0.1803278689\n",
      "HR_5_11_UE_CNT_RAT: 0.04098360656\n",
      "HR_12_13_UE_CNT_RAT: 0.393442623\n",
      "HR_14_17_UE_CNT_RAT: 0.2704918033\n",
      "HR_18_22_UE_CNT_RAT: 0.2950819672\n",
      "HR_23_4_UE_CNT_RAT: 0.0\n",
      "LOCAL_UE_CNT_RAT: 0.6627218935\n",
      "RC_M12_MAL_CUS_CNT_RAT: 0.396\n",
      "RC_M12_FME_CUS_CNT_RAT: 0.604\n",
      "RC_M12_AGE_UND_20_CUS_CNT_RAT: 0.138\n",
      "RC_M12_AGE_30_CUS_CNT_RAT: 0.268\n",
      "RC_M12_AGE_40_CUS_CNT_RAT: 0.351\n",
      "RC_M12_AGE_50_CUS_CNT_RAT: 0.18\n",
      "RC_M12_AGE_OVR_60_CUS_CNT_RAT: 0.064\n",
      "\n",
      "YM: 202307\n",
      "MCT_NM: 제주포레스트주식회사 포메인제주노형점\n",
      "OP_YMD: 20200420\n",
      "TYPE: T9\n",
      "MCT_TYPE: 동남아/인도음식\n",
      "temp_05_11: 27.58110599\n",
      "temp_12_13: 29.90322581\n",
      "temp_14_17: 29.92258065\n",
      "temp_18_22: 28.15612903\n",
      "temp_23_04: 26.80430108\n",
      "TEMP_AVG: 28.47346851\n",
      "latitude: 33.4842637\n",
      "longitude: 126.4798582\n",
      "Polygon: P3\n",
      "area: 북부\n",
      "ADDR: 제주 제주시 노형동 3783-2번지 3층\n",
      "RANK_CNT: 3\n",
      "RANK_AMT: 3\n",
      "RANK_MEAN: 4\n",
      "MON_UE_CNT_RAT: 0.1475409836\n",
      "TUE_UE_CNT_RAT: 0.1557377049\n",
      "WED_UE_CNT_RAT: 0.1967213115\n",
      "THU_UE_CNT_RAT: 0.106557377\n",
      "FRI_UE_CNT_RAT: 0.1147540984\n",
      "SAT_UE_CNT_RAT: 0.09836065574\n",
      "SUN_UE_CNT_RAT: 0.1803278689\n",
      "HR_5_11_UE_CNT_RAT: 0.04098360656\n",
      "HR_12_13_UE_CNT_RAT: 0.393442623\n",
      "HR_14_17_UE_CNT_RAT: 0.2704918033\n",
      "HR_18_22_UE_CNT_RAT: 0.2950819672\n",
      "HR_23_4_UE_CNT_RAT: 0.0\n",
      "LOCAL_UE_CNT_RAT: 0.6627218935\n",
      "RC_M12_MAL_CUS_CNT_RAT: 0.396\n",
      "RC_M12_FME_CUS_CNT_RAT: 0.604\n",
      "RC_M12_AGE_UND_20_CUS_CNT_RAT: 0.138\n",
      "RC_M12_AGE_30_CUS_CNT_RAT: 0.268\n",
      "RC_M12_AGE_40_CUS_CNT_RAT: 0.351\n",
      "RC_M12_AGE_50_CUS_CNT_RAT: 0.18\n",
      "RC_M12_AGE_OVR_60_CUS_CNT_RAT: 0.064\n",
      "\n",
      "YM: 202311\n",
      "MCT_NM: 제주포레스트주식회사 포메인제주노형점\n",
      "OP_YMD: 20200420\n",
      "TYPE: T9\n",
      "MCT_TYPE: 동남아/인도음식\n",
      "temp_05_11: 13.14285714\n",
      "temp_12_13: 15.77166667\n",
      "temp_14_17: 15.54166667\n",
      "temp_18_22: 13.40533333\n",
      "temp_23_04: 12.57055556\n",
      "TEMP_AVG: 14.08641587\n",
      "latitude: 33.4842637\n",
      "longitude: 126.4798582\n",
      "Polygon: P3\n",
      "area: 북부\n",
      "ADDR: 제주 제주시 노형동 3783-2번지 3층\n",
      "RANK_CNT: 2\n",
      "RANK_AMT: 3\n",
      "RANK_MEAN: 4\n",
      "MON_UE_CNT_RAT: 0.1384615385\n",
      "TUE_UE_CNT_RAT: 0.2\n",
      "WED_UE_CNT_RAT: 0.1692307692\n",
      "THU_UE_CNT_RAT: 0.1076923077\n",
      "FRI_UE_CNT_RAT: 0.1307692308\n",
      "SAT_UE_CNT_RAT: 0.1307692308\n",
      "SUN_UE_CNT_RAT: 0.1230769231\n",
      "HR_5_11_UE_CNT_RAT: 0.02307692308\n",
      "HR_12_13_UE_CNT_RAT: 0.3692307692\n",
      "HR_14_17_UE_CNT_RAT: 0.2923076923\n",
      "HR_18_22_UE_CNT_RAT: 0.3153846154\n",
      "HR_23_4_UE_CNT_RAT: 0.0\n",
      "LOCAL_UE_CNT_RAT: 0.6666666667\n",
      "RC_M12_MAL_CUS_CNT_RAT: 0.39\n",
      "RC_M12_FME_CUS_CNT_RAT: 0.61\n",
      "RC_M12_AGE_UND_20_CUS_CNT_RAT: 0.127\n",
      "RC_M12_AGE_30_CUS_CNT_RAT: 0.26\n",
      "RC_M12_AGE_40_CUS_CNT_RAT: 0.362\n",
      "RC_M12_AGE_50_CUS_CNT_RAT: 0.183\n",
      "RC_M12_AGE_OVR_60_CUS_CNT_RAT: 0.068\n",
      "]<==참조 문서 끝\n",
      "answer1: 제주도 북부에 위치한 로컬 주민들에게 인기 많은 맛집을 추천드립니다. \n",
      "제주포레스트주식회사 포메인제주노형점은 북부에 위치한 동남아/인도음식 맛집입니다. 로컬 주민들에게 인기가 많으며, 특히 12시부터 13시 사이에 방문객이 많습니다. 제주 제주시 노형동 3783-2번지 3층에 위치하고 있습니다. \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 9) 질의응답 테스트\n",
    "answer = chain.invoke(\"우도에서 로컬 주민들에게 인기많은 맛집을 알려줘\")\n",
    "print(f\"answer1: {answer}\\n\\n\")\n",
    "\n",
    "# answer = chain.invoke(\"제주도 북부에서 로컬 사람들에게 인기 많은 맛집을 추천해줘\")\n",
    "# print(f\"answer2: {answer}\")\n",
    "\n",
    "# answer = chain.invoke(\"40대 남성들에게 인기가 많은 맛집 추천해줘\")\n",
    "# print(f\"answer2: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"..\\data\\sample_1000_with_meta.csv\", encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                업종\n",
       "1            STRING\n",
       "2       요식관련 30개 업종\n",
       "3               햄버거\n",
       "4                일식\n",
       "           ...     \n",
       "998             가정식\n",
       "999         단품요리 전문\n",
       "1000            햄버거\n",
       "1001             피자\n",
       "1002           스테이크\n",
       "Name: MCT_TYPE, Length: 1003, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['MCT_TYPE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_25532\\425915403.py:6: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorstore = Chroma(embedding_function=lambda x: model(**tokenizer(x, return_tensors=\"pt\", padding=True, truncation=True)).last_hidden_state.mean(dim=1).detach().numpy())\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'embed_documents'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m tokenizer(text, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     12\u001b[0m     embedding \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\u001b[38;5;241m.\u001b[39mlast_hidden_state\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()  \u001b[38;5;66;03m# 임베딩을 NumPy 배열로 변환\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m     \u001b[43mvectorstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 텍스트 데이터\u001b[39;49;00m\n\u001b[0;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 메타데이터\u001b[39;49;00m\n\u001b[0;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m]\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 임베딩\u001b[39;49;00m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m벡터스토어에 저장 완료\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\workspaces\\llmGeminiTest\\.venv\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:277\u001b[0m, in \u001b[0;36mChroma.add_texts\u001b[1;34m(self, texts, metadatas, ids, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(texts)\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 277\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embedding_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m(texts)\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metadatas:\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;66;03m# fill metadatas with empty dicts if somebody\u001b[39;00m\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;66;03m# did not specify metadata for all texts\u001b[39;00m\n\u001b[0;32m    281\u001b[0m     length_diff \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(texts) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(metadatas)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'embed_documents'"
     ]
    }
   ],
   "source": [
    "# 3) 벡터스토어에 저장 (ChromaDB)\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# 벡터스토어 생성\n",
    "vectorstore = Chroma(embedding_function=lambda x: model(**tokenizer(x, return_tensors=\"pt\", padding=True, truncation=True)).last_hidden_state.mean(dim=1).detach().numpy())\n",
    "\n",
    "# 4) 벡터와 메타데이터를 벡터스토어에 저장\n",
    "for page in pages:\n",
    "    text = page.page_content\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    embedding = model(**inputs).last_hidden_state.mean(dim=1).detach().numpy()  # 임베딩을 NumPy 배열로 변환\n",
    "    \n",
    "    vectorstore.add_texts(\n",
    "        texts=[text],  # 텍스트 데이터\n",
    "        metadatas=[{\"metadata\": page.metadata}],  # 메타데이터\n",
    "        embeddings=[embedding]  # 임베딩\n",
    "    )\n",
    "\n",
    "print(\"벡터스토어에 저장 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28f2ac2491d54b47bc97eccfd7f3fd18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cabba94b4b224d2b8669b8df2f5d364f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28b55f4a96084a5aa9a6e49aac76f2ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c64028d1ccb4d09a16704cdf8a50d70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5841f5b961e4ea9bc081296bb3f5ef2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "893dc8bae300427ea8571aa7cf0889fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "843f8351eee14818a2d6006fbb724c90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5c84bb015e0432fa5e7914bc5278c6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a20fbdef7a94acb88a5f334d6bea62c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdb98ab10c564f33a59cc2d7632dccad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\workspaces\\llmGeminiTest\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c31677e609d84ba9a9d8e74324fc5942",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3) 임베딩 & 벡터스토어 생성\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# from langchain.llms import HuggingFaceHub\n",
    "# from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "vectorstore = FAISS.from_documents(documents=pages,\n",
    "                                   embedding=HuggingFaceEmbeddings()\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chroma DB 적용\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=pages, embedding=HuggingFaceEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단계 4: 검색(Search)\n",
    "# 뉴스에 포함되어 있는 정보를 검색하고 생성합니다.\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단계 5: 프롬프트 생성(Create Prompt)\n",
    "from langchain import hub\n",
    "\n",
    "# 프롬프트를 생성합니다.\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단계 6: 언어모델 생성(Create LLM)\n",
    "# 모델(LLM) 을 생성합니다.\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    # 검색한 문서 결과를 하나의 문단으로 합쳐줍니다.\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단계 7: 체인 생성(Create Chain)\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단계 8: 체인 실행(Run Chain)\n",
    "# 문서에 대한 질의를 입력하고, 답변을 출력합니다.\n",
    "question = \"부영그룹의 출산 장려 정책에 대해 설명해주세요\"\n",
    "response = rag_chain.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 출력\n",
    "print(f\"URL: {url}\")\n",
    "print(f\"문서의 수: {len(docs)}\")\n",
    "print(\"===\" * 20)\n",
    "print(f\"[HUMAN]\\n{question}\\n\")\n",
    "print(f\"[AI]\\n{response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Using `low_cpu_mem_usage=True` or a `device_map` requires Accelerate: `pip install accelerate`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# HuggingFace Repository ID\u001b[39;00m\n\u001b[0;32m      2\u001b[0m repo_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjhgan/ko-sroberta-multitask\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# device_map: 모델이 GPU로 이동되도록 함\u001b[39;49;00m\n\u001b[0;32m      5\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# load_in_4bit: 리소스 요구사항을 줄이기 위해 4비트 동적 양자화를 적용\u001b[39;49;00m\n\u001b[0;32m      6\u001b[0m \u001b[43m  \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\workspaces\\llmGeminiTest\\.venv\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:564\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[1;32m--> 564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    570\u001b[0m )\n",
      "File \u001b[1;32mc:\\workspaces\\llmGeminiTest\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py:3318\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   3314\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   3315\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeepSpeed Zero-3 is not compatible with `low_cpu_mem_usage=True` or with passing a `device_map`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3316\u001b[0m         )\n\u001b[0;32m   3317\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_accelerate_available():\n\u001b[1;32m-> 3318\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m   3319\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing `low_cpu_mem_usage=True` or a `device_map` requires Accelerate: `pip install accelerate`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3320\u001b[0m         )\n\u001b[0;32m   3322\u001b[0m \u001b[38;5;66;03m# handling bnb config from kwargs, remove after `load_in_{4/8}bit` deprecation.\u001b[39;00m\n\u001b[0;32m   3323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m load_in_4bit \u001b[38;5;129;01mor\u001b[39;00m load_in_8bit:\n",
      "\u001b[1;31mImportError\u001b[0m: Using `low_cpu_mem_usage=True` or a `device_map` requires Accelerate: `pip install accelerate`"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "\n",
    "# HuggingFace Repository ID\n",
    "repo_id = \"jhgan/ko-sroberta-multitask\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "  # device_map: 모델이 GPU로 이동되도록 함\n",
    "  # load_in_4bit: 리소스 요구사항을 줄이기 위해 4비트 동적 양자화를 적용\n",
    "  repo_id, device_map='auto', load_in_4bit=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BertTokenizerFast' object has no attribute 'embed_documents'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mChroma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./database\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\workspaces\\llmGeminiTest\\.venv\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:878\u001b[0m, in \u001b[0;36mChroma.from_documents\u001b[1;34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[0;32m    876\u001b[0m texts \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m    877\u001b[0m metadatas \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m--> 878\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpersist_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\workspaces\\llmGeminiTest\\.venv\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:836\u001b[0m, in \u001b[0;36mChroma.from_texts\u001b[1;34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[0;32m    828\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatch_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_batches\n\u001b[0;32m    830\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m create_batches(\n\u001b[0;32m    831\u001b[0m         api\u001b[38;5;241m=\u001b[39mchroma_collection\u001b[38;5;241m.\u001b[39m_client,\n\u001b[0;32m    832\u001b[0m         ids\u001b[38;5;241m=\u001b[39mids,\n\u001b[0;32m    833\u001b[0m         metadatas\u001b[38;5;241m=\u001b[39mmetadatas,\n\u001b[0;32m    834\u001b[0m         documents\u001b[38;5;241m=\u001b[39mtexts,\n\u001b[0;32m    835\u001b[0m     ):\n\u001b[1;32m--> 836\u001b[0m         \u001b[43mchroma_collection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    837\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    838\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[43m            \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    840\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    841\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    842\u001b[0m     chroma_collection\u001b[38;5;241m.\u001b[39madd_texts(texts\u001b[38;5;241m=\u001b[39mtexts, metadatas\u001b[38;5;241m=\u001b[39mmetadatas, ids\u001b[38;5;241m=\u001b[39mids)\n",
      "File \u001b[1;32mc:\\workspaces\\llmGeminiTest\\.venv\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:277\u001b[0m, in \u001b[0;36mChroma.add_texts\u001b[1;34m(self, texts, metadatas, ids, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(texts)\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 277\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embedding_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m(texts)\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metadatas:\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;66;03m# fill metadatas with empty dicts if somebody\u001b[39;00m\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;66;03m# did not specify metadata for all texts\u001b[39;00m\n\u001b[0;32m    281\u001b[0m     length_diff \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(texts) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(metadatas)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'BertTokenizerFast' object has no attribute 'embed_documents'"
     ]
    }
   ],
   "source": [
    "Chroma.from_documents(pages, model, persist_directory=\"./database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>YM</th>\n",
       "      <th>MCT_NM</th>\n",
       "      <th>OP_YMD</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>MCT_TYPE</th>\n",
       "      <th>temp_05_11</th>\n",
       "      <th>temp_12_13</th>\n",
       "      <th>temp_14_17</th>\n",
       "      <th>temp_18_22</th>\n",
       "      <th>...</th>\n",
       "      <th>HR_18_22_UE_CNT_RAT</th>\n",
       "      <th>HR_23_4_UE_CNT_RAT</th>\n",
       "      <th>LOCAL_UE_CNT_RAT</th>\n",
       "      <th>RC_M12_MAL_CUS_CNT_RAT</th>\n",
       "      <th>RC_M12_FME_CUS_CNT_RAT</th>\n",
       "      <th>RC_M12_AGE_UND_20_CUS_CNT_RAT</th>\n",
       "      <th>RC_M12_AGE_30_CUS_CNT_RAT</th>\n",
       "      <th>RC_M12_AGE_40_CUS_CNT_RAT</th>\n",
       "      <th>RC_M12_AGE_50_CUS_CNT_RAT</th>\n",
       "      <th>RC_M12_AGE_OVR_60_CUS_CNT_RAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58148</td>\n",
       "      <td>202311</td>\n",
       "      <td>별미돈</td>\n",
       "      <td>20211008</td>\n",
       "      <td>T1</td>\n",
       "      <td>가정식</td>\n",
       "      <td>13.142857</td>\n",
       "      <td>15.771667</td>\n",
       "      <td>15.541667</td>\n",
       "      <td>13.405333</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.377</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53199</td>\n",
       "      <td>202310</td>\n",
       "      <td>한라산과자점</td>\n",
       "      <td>20210316</td>\n",
       "      <td>T13</td>\n",
       "      <td>베이커리</td>\n",
       "      <td>19.402765</td>\n",
       "      <td>22.798387</td>\n",
       "      <td>22.369355</td>\n",
       "      <td>19.323226</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051303</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44383</td>\n",
       "      <td>202308</td>\n",
       "      <td>그럼외도</td>\n",
       "      <td>20200207</td>\n",
       "      <td>T6</td>\n",
       "      <td>단품요리 전문</td>\n",
       "      <td>28.137788</td>\n",
       "      <td>30.480645</td>\n",
       "      <td>30.813710</td>\n",
       "      <td>28.823226</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029126</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.218391</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63422</td>\n",
       "      <td>202312</td>\n",
       "      <td>숯검댕이2호점</td>\n",
       "      <td>20180904</td>\n",
       "      <td>T1</td>\n",
       "      <td>가정식</td>\n",
       "      <td>9.402857</td>\n",
       "      <td>12.151667</td>\n",
       "      <td>11.806667</td>\n",
       "      <td>9.794667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.226131</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.482</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39190</td>\n",
       "      <td>202307</td>\n",
       "      <td>거멍국수</td>\n",
       "      <td>20150702</td>\n",
       "      <td>T6</td>\n",
       "      <td>단품요리 전문</td>\n",
       "      <td>25.585714</td>\n",
       "      <td>26.988710</td>\n",
       "      <td>26.583871</td>\n",
       "      <td>25.608387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083749</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.303</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      YM   MCT_NM    OP_YMD TYPE MCT_TYPE  temp_05_11  \\\n",
       "0       58148  202311      별미돈  20211008   T1      가정식   13.142857   \n",
       "1       53199  202310   한라산과자점  20210316  T13     베이커리   19.402765   \n",
       "2       44383  202308     그럼외도  20200207   T6  단품요리 전문   28.137788   \n",
       "3       63422  202312  숯검댕이2호점  20180904   T1      가정식    9.402857   \n",
       "4       39190  202307     거멍국수  20150702   T6  단품요리 전문   25.585714   \n",
       "\n",
       "   temp_12_13  temp_14_17  temp_18_22  ...  HR_18_22_UE_CNT_RAT  \\\n",
       "0   15.771667   15.541667   13.405333  ...             1.000000   \n",
       "1   22.798387   22.369355   19.323226  ...             0.000000   \n",
       "2   30.480645   30.813710   28.823226  ...             0.029126   \n",
       "3   12.151667   11.806667    9.794667  ...             0.764706   \n",
       "4   26.988710   26.583871   25.608387  ...             0.081081   \n",
       "\n",
       "   HR_23_4_UE_CNT_RAT  LOCAL_UE_CNT_RAT  RC_M12_MAL_CUS_CNT_RAT  \\\n",
       "0            0.000000          0.800000                   0.676   \n",
       "1            0.000000          0.051303                   0.270   \n",
       "2            0.000000          0.218391                   0.320   \n",
       "3            0.235294          0.226131                   0.518   \n",
       "4            0.000000          0.083749                   0.593   \n",
       "\n",
       "  RC_M12_FME_CUS_CNT_RAT RC_M12_AGE_UND_20_CUS_CNT_RAT  \\\n",
       "0                  0.324                         0.101   \n",
       "1                  0.730                         0.519   \n",
       "2                  0.680                         0.466   \n",
       "3                  0.482                         0.333   \n",
       "4                  0.407                         0.178   \n",
       "\n",
       "  RC_M12_AGE_30_CUS_CNT_RAT RC_M12_AGE_40_CUS_CNT_RAT  \\\n",
       "0                     0.251                     0.377   \n",
       "1                     0.276                     0.119   \n",
       "2                     0.335                     0.100   \n",
       "3                     0.205                     0.221   \n",
       "4                     0.303                     0.247   \n",
       "\n",
       "   RC_M12_AGE_50_CUS_CNT_RAT RC_M12_AGE_OVR_60_CUS_CNT_RAT  \n",
       "0                      0.198                         0.072  \n",
       "1                      0.066                         0.019  \n",
       "2                      0.081                         0.018  \n",
       "3                      0.179                         0.062  \n",
       "4                      0.188                         0.084  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/llm_sample_data_with_every_area.csv\", encoding='cp949')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "496    제주 제주시 오라이동 3173번지 1층\n",
       "Name: ADDR, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['MCT_NM'] == '(유)아웃백스테이크하우스 제주아일랜드점']['ADDR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
